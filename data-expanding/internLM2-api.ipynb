{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openxlab\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_internlm_token(ak: str, sk: str):\n",
    "    token = openxlab.xlab.handler.user_token.get_jwt(ak, sk)\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ak = 'bbdjyrjm3z9abagxzpmw'\n",
    "sk = '17wlpekdraq9z5jav6qmbava4aq6onvgbkzl2moe'\n",
    "\n",
    "token = get_internlm_token(ak, sk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def internLM_chat(prompt:str):\n",
    "    url = 'https://internlm-chat.intern-ai.org.cn/puyu/api/v1/chat/completion'\n",
    "    header = {\n",
    "        'Content-Type': 'application/json',\n",
    "        \"Authorization\": token\n",
    "    }\n",
    "    data = {\n",
    "        \"model\": \"internlm2-latest\",  \n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"text\": prompt},\n",
    "            ],\n",
    "        \"n\": 1,\n",
    "        \"temperature\": 0.5,\n",
    "        \"top_p\": 0.5,\n",
    "        \"disable_report\": False\n",
    "    }\n",
    "    res = requests.post(url, headers=header, data=json.dumps(data))\n",
    "    response = res.json()[\"data\"][\"choices\"][0][\"text\"]\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你好！有什么我可以帮助你的吗？'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "internLM_chat('你好')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: 特朗普是那一年总统？\n",
      "Thought: 为了回答这个问题，我需要调用夸克搜索API来查找特朗普成为总统的年份。\n",
      "Action: quark_search\n",
      "Action Input: {\"name\": \"search_query\", \"description\": \"搜索关键词或短语\", \"required\": true, \"schema\": {\"type\": \"string\"}}, {\"search_query\": \"特朗普 总统 年份\"}\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "quark_search: Call this tool to interact with the 夸克搜索 API. What is the 夸克搜索 API useful for? 夸克搜索是一个通用搜索引擎，可用于访问互联网、查询百科知识、了解时事新闻等。 Parameters: [{\"name\": \"search_query\", \"description\": \"搜索关键词或短语\", \"required\": true, \"schema\": {\"type\": \"string\"}}] Format the arguments as a JSON object.\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [quark_search]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can be repeated zero or more times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: 特朗普是那一年总统？\n",
    "\"\"\"\n",
    "response = internLM_chat(text)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_latest_plugin_call(text):\n",
    "    plugin_name, plugin_args = '', ''\n",
    "    i = text.rfind('\\nAction:')\n",
    "    j = text.rfind('\\nAction Input:')\n",
    "    k = text.rfind('\\nObservation:')\n",
    "    if 0 <= i < j:  # If the text has `Action` and `Action input`,\n",
    "        if k < j:  # but does not contain `Observation`,\n",
    "            # then it is likely that `Observation` is ommited by the LLM,\n",
    "            # because the output text may have discarded the stop word.\n",
    "            text = text.rstrip() + '\\nObservation:'  # Add it back.\n",
    "        k = text.rfind('\\nObservation:')\n",
    "        plugin_name = text[i + len('\\nAction:') : j].strip()\n",
    "        plugin_args = text[j + len('\\nAction Input:') : k].strip()\n",
    "        text = text[:k]\n",
    "    return plugin_name, plugin_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('google_search', '{\"search_query\": \"周杰伦 老婆\"}')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_txt = \"\"\"\n",
    "User's Query:\n",
    "你好\n",
    "\n",
    "Qwen's Response:\n",
    "Thought: 提供的工具对回答该问题帮助较小，我将不使用工具直接作答。\n",
    "Final Answer: 你好！很高兴见到你。有什么我可以帮忙的吗？\n",
    "\n",
    "User's Query:\n",
    "搜索一下谁是周杰伦\n",
    "\n",
    "Qwen's Response:\n",
    "Thought: 我应该使用Google搜索查找相关信息。\n",
    "Action: google_search\n",
    "Action Input: {\"search_query\": \"周杰伦\"}\n",
    "Observation: Jay Chou is a Taiwanese singer, songwriter, record producer, rapper, actor, television personality, and businessman.\n",
    "Thought: I now know the final answer.\n",
    "Final Answer: 周杰伦（Jay Chou）是一位来自台湾的歌手、词曲创作人、音乐制作人、说唱歌手、演员、电视节目主持人和企业家。他以其独特的音乐风格和才华在华语乐坛享有很高的声誉。\n",
    "\n",
    "User's Query:\n",
    "再搜下他老婆是谁\n",
    "\n",
    "Qwen's Response:\n",
    "Thought: 我应该使用Google搜索查找相关信息。\n",
    "Action: google_search\n",
    "Action Input: {\"search_query\": \"周杰伦 老婆\"}\n",
    "Observation: Hannah Quinlivan\n",
    "Thought: I now know the final answer.\n",
    "Final Answer: 周杰伦的老婆是Hannah Quinlivan，她是一位澳大利亚籍的模特和演员。两人于2015年结婚，并育有一子。\n",
    "\"\"\"\n",
    "\n",
    "parse_latest_plugin_call(test_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(579, 601, 642)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = test_txt.rfind('\\nAction:')\n",
    "j = test_txt.rfind('\\nAction Input:')\n",
    "k = test_txt.rfind('\\nObservation:')\n",
    "i, j, k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将一个插件的关键信息拼接成一段文本的模版。\n",
    "TOOL_DESC = \"\"\"{name_for_model}: Call this tool to interact with the {name_for_human} API. What is the {name_for_human} API useful for? {description_for_model} Parameters: {parameters}\"\"\"\n",
    "\n",
    "# ReAct prompting 的 instruction 模版，将包含插件的详细信息。\n",
    "PROMPT_REACT = \"\"\"Answer the following questions as best you can. You have access to the following APIs:\n",
    "\n",
    "{tools_text}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tools_name_text}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can be repeated zero or more times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {query}\"\"\"\n",
    "\n",
    "tools = [\n",
    "        {\n",
    "            'name_for_human': '谷歌搜索',\n",
    "            'name_for_model': 'google_search',\n",
    "            'description_for_model': '谷歌搜索是一个通用搜索引擎，可用于访问互联网、查询百科知识、了解时事新闻等。',\n",
    "            'parameters': [\n",
    "                {\n",
    "                    'name': 'search_query',\n",
    "                    'description': '搜索关键词或短语',\n",
    "                    'required': True,\n",
    "                    'schema': {'type': 'string'},\n",
    "                }\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            'name_for_human': '文生图',\n",
    "            'name_for_model': 'image_gen',\n",
    "            'description_for_model': '文生图是一个AI绘画（图像生成）服务，输入文本描述，返回根据文本作画得到的图片的URL',\n",
    "            'parameters': [\n",
    "                {\n",
    "                    'name': 'prompt',\n",
    "                    'description': '英文关键词，描述了希望图像具有什么内容',\n",
    "                    'required': True,\n",
    "                    'schema': {'type': 'string'},\n",
    "                }\n",
    "            ],\n",
    "        },\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_input_text(chat_history, list_of_plugin_info) -> str:\n",
    "    # 候选插件的详细信息\n",
    "    tools_text = []\n",
    "    for plugin_info in list_of_plugin_info:\n",
    "        tool = TOOL_DESC.format(\n",
    "            name_for_model=plugin_info[\"name_for_model\"],\n",
    "            name_for_human=plugin_info[\"name_for_human\"],\n",
    "            description_for_model=plugin_info[\"description_for_model\"],\n",
    "            parameters=json.dumps(plugin_info[\"parameters\"], ensure_ascii=False),\n",
    "        )\n",
    "        if plugin_info.get('args_format', 'json') == 'json':\n",
    "            tool += \" Format the arguments as a JSON object.\"\n",
    "        elif plugin_info['args_format'] == 'code':\n",
    "            tool += ' Enclose the code within triple backticks (`) at the beginning and end of the code.'\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        tools_text.append(tool)\n",
    "    tools_text = '\\n\\n'.join(tools_text)\n",
    "\n",
    "    # 候选插件的代号\n",
    "    tools_name_text = ', '.join([plugin_info[\"name_for_model\"] for plugin_info in list_of_plugin_info])\n",
    "\n",
    "    im_start = '<|im_start|>'\n",
    "    im_end = '<|im_end|>'\n",
    "    prompt = f'{im_start}system\\nYou are a helpful assistant.{im_end}'\n",
    "    for i, (query, response) in enumerate(chat_history):\n",
    "        if list_of_plugin_info:  # 如果有候选插件\n",
    "            # 倒数第一轮或倒数第二轮对话填入详细的插件信息，但具体什么位置填可以自行判断\n",
    "            if (len(chat_history) == 1) or (i == len(chat_history) - 2):\n",
    "                query = PROMPT_REACT.format(\n",
    "                    tools_text=tools_text,\n",
    "                    tools_name_text=tools_name_text,\n",
    "                    query=query,\n",
    "                )\n",
    "        query = query.lstrip('\\n').rstrip()  # 重要！若不 strip 会与训练时数据的构造方式产生差异。\n",
    "        response = response.lstrip('\\n').rstrip()  # 重要！若不 strip 会与训练时数据的构造方式产生差异。\n",
    "        # 使用续写模式（text completion）时，需要用如下格式区分用户和AI：\n",
    "        prompt += f\"\\n{im_start}user\\n{query}{im_end}\"\n",
    "        prompt += f\"\\n{im_start}assistant\\n{response}{im_end}\"\n",
    "\n",
    "    prompt.endswith(f\"\\n{im_start}assistant\\n{im_end}\")\n",
    "    prompt = prompt[: -len(f'{im_end}')]\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metagpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
